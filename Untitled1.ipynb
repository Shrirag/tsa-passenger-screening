{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shriragkodoor/anaconda/envs/ml_project/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from vectorize import vectorize\n",
    "import pickle, time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file paths\n",
    "DATA_PATH = '/Users/shriragkodoor/Downloads/stage1_aps' # Path of directory containing 'aps' files\n",
    "LABEL_PATH = '/Users/shriragkodoor/Downloads/stage1_labels.csv' # Path of csv file with labels\n",
    "\n",
    "# Pickle dump file paths\n",
    "VECTORS_PATH = '/Users/shriragkodoor/Downloads/ml_test/vectors.p'\n",
    "RFC_GRID_SEARCH_PATH = '/Users/shriragkodoor/Downloads/ml_test/rgc_grid.p'\n",
    "GBC_GRID_SEARCH_PATH = '/Users/shriragkodoor/Downloads/ml_test/gbc_grid.p'\n",
    "XGB_GRID_SEARCH_PATH = '/Users/shriragkodoor/Downloads/ml_test/xgb_grid.p'\n",
    "FINAL_RESULTS_PATH = '/Users/shriragkodoor/Downloads/ml_test/final.p'\n",
    "\n",
    "# Result paths\n",
    "CLASS_DIST_BAR_GRAPH_PATH = '/Users/shriragkodoor/Downloads/ml_test/dist_graph.png'\n",
    "RFC_GRID_SEARCH_GRAPH_PATH = '/Users/shriragkodoor/Downloads/ml_test/rfc_grid.png'\n",
    "GBC_GRID_SEARCH_GRAPH_PATH = '/Users/shriragkodoor/Downloads/ml_test/gbc_grid.png'\n",
    "XGB_GRID_SEARCH_GRAPH_PATH = '/Users/shriragkodoor/Downloads/ml_test/xgb_grid.png'\n",
    "FINAL_RESULTS_GRAPH_PATH = '/Users/shriragkodoor/Downloads/ml_test/final_results.png'\n",
    "\n",
    "# ScikitLearn parameters\n",
    "NUM_CORES = 2 # Number of cores available on machine\n",
    "GRID_SEARCH_CV_FOLDS = 3 # Number of folds for parameter selection cross validation\n",
    "CV_FOLDS = 3 # Number of folds for final cross validation\n",
    "\n",
    "RANDOM_STATE = np.random.RandomState(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/shriragkodoor/Downloads/ml_test/dist_graph.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-455bbb1b3f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLASS_DIST_BAR_GRAPH_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mclass_dist_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLABEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-145-455bbb1b3f2a>\u001b[0m in \u001b[0;36mclass_dist_bar\u001b[0;34m(LABEL_PATH)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class Distribution Among Zones\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLASS_DIST_BAR_GRAPH_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mclass_dist_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLABEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml_project/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml_project/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, **kwargs)\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml_project/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2257\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2259\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2260\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ml_project/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/shriragkodoor/Downloads/ml_test/dist_graph.png'"
     ]
    }
   ],
   "source": [
    "def class_dist_bar(LABEL_PATH):\n",
    "    \n",
    "    df = pd.read_csv(LABEL_PATH)\n",
    "    \n",
    "    zone_count = {}\n",
    "    for i in range(1,18):\n",
    "        temp = df[df['Id'].str.endswith('Zone'+str(i))]\n",
    "        zone_count[i] = (np.sum(temp['Probability']==0), np.sum(temp['Probability']==1))\n",
    "\n",
    "    neg_class = [zone_count[i][0] for i in zone_count]\n",
    "    pos_class = [zone_count[i][1] for i in zone_count]\n",
    "\n",
    "    plt.figure(figsize = (6,6))\n",
    "    width = 0.8\n",
    "    indices = np.arange(len(neg_class))\n",
    "    plt.bar(indices, neg_class, width=width, \n",
    "            color='g', label='Negative Class')\n",
    "    plt.bar(indices, pos_class, \n",
    "            width=0.4*width, color='r', alpha=0.5, label='Positive Class')\n",
    "    plt.xticks(indices, \n",
    "               ['{}'.format(i+1) for i in range(len(neg_class))] )\n",
    "    plt.xlabel(\"Body Zone\")\n",
    "    plt.ylabel(\"Instances\")\n",
    "    plt.title(\"Class Distribution Among Zones\")\n",
    "    plt.legend()\n",
    "    plt.savefig(CLASS_DIST_BAR_GRAPH_PATH)\n",
    "\n",
    "class_dist_bar(LABEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_selection_heat_map(results, px_len, py_len, CV_FOLDS, GRAPH_PATH):\n",
    "\n",
    "    params = results['params']\n",
    "    param_scores = []\n",
    "    for i in range(CV_FOLDS):\n",
    "        param_scores.append(results['split%s_test_score' % (i)])\n",
    "\n",
    "    param_scores = [sum(x)/len(x) for x in np.asarray(param_scores).transpose()]\n",
    "\n",
    "    ps = [] \n",
    "    for i in range(len(params)): \n",
    "        ps.append({\n",
    "            'max_depth': params[i]['max_depth'],\n",
    "            'n_estimators': params[i]['n_estimators'],\n",
    "            'score': param_scores[i]\n",
    "        })\n",
    "\n",
    "    x, y = [], []\n",
    "    for i in range(len(ps)): \n",
    "        if ps[i]['max_depth'] not in x: x.append(ps[i]['max_depth'])\n",
    "        if ps[i]['n_estimators'] not in y: y.append(ps[i]['n_estimators'])\n",
    "    z = np.asarray([ps[i]['score'] for i in range(len(ps))]).ravel()\n",
    "\n",
    "    arr = []\n",
    "    for i in range(0, len(params), px_len):\n",
    "        row = []\n",
    "        for j in range(px_len): row.append(z[i+j])\n",
    "        arr.append(row)\n",
    "\n",
    "    fig, axarr = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    plot = axarr.imshow(arr, aspect='auto')\n",
    "    axarr.set_xticks([i for i in range(len(y))], minor=False)\n",
    "    axarr.set_yticks([i for i in range(len(x))], minor=False)\n",
    "    axarr.set_xticklabels(y, minor=False)\n",
    "    axarr.set_yticklabels(x, minor=False)\n",
    "    axarr.set_xlabel('Number of Estimators')\n",
    "    axarr.set_ylabel('Max Depth')\n",
    "    fig.colorbar(plot)\n",
    "    plt.savefig(GRAPH_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialization\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0a83698bce92a6824dcc37c1d7fc31f5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1c2c1c9a0672>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVECTORS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ys'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/shriragkodoor/Downloads/ml_test/vectors.p'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1c2c1c9a0672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFINAL_RESULTS_GRAPH_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-1c2c1c9a0672>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'xs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ys'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVECTORS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tsa-passenger-screening/vectorize.py\u001b[0m in \u001b[0;36mvectorize\u001b[0;34m(data_path, label_path)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mzones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mzones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mbody_zone_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '0a83698bce92a6824dcc37c1d7fc31f5'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "\n",
    "    ########################## \n",
    "    # Dataset initialization # \n",
    "    ########################## \n",
    "\n",
    "    print('Dataset initialization')\n",
    "    \n",
    "    try :\n",
    "\n",
    "        vectors = pickle.load(open(VECTORS_PATH, 'rb'))\n",
    "        xs, ys = vectors['xs'], vectors['ys']\n",
    "\n",
    "    except FileNotFoundError:\n",
    "\n",
    "        xs, ys = vectorize(DATA_PATH, LABEL_PATH)\n",
    "        pickle.dump({ 'xs': xs, 'ys': ys }, open(VECTORS_PATH, 'wb'))\n",
    "\n",
    "    ##########################\n",
    "    # Parameter Optimization #\n",
    "    ##########################\n",
    "    \n",
    "    print('Parameter Optimization')\n",
    "\n",
    "    # xi, yi is the subset of the dataset used for optimizing the hyperparameters\n",
    "    xi, yi = xs[1], ys[1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(xi, yi, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Random Forest Parameter Grid\n",
    "    rfc_param_grid = [{\n",
    "        'n_estimators': [i for i in range(10, 50, 10)],\n",
    "        'max_depth': [i for i in range(1, 5)],\n",
    "        'n_jobs': [NUM_CORES],\n",
    "        'random_state': [RANDOM_STATE] \n",
    "    }]\n",
    "    rfc_px_len = len(rfc_param_grid[0]['n_estimators'])\n",
    "    rfc_py_len = len(rfc_param_grid[0]['max_depth'])\n",
    "\n",
    "    # Gradient Boost Parameter Grid\n",
    "    gbc_param_grid = [{\n",
    "        'n_estimators': [i for i in range(10, 50, 10)],\n",
    "        'max_depth': [i for i in range(1, 5)],\n",
    "        'random_state': [RANDOM_STATE] \n",
    "    }]\n",
    "    gbc_px_len = len(gbc_param_grid[0]['n_estimators'])\n",
    "    gbc_py_len = len(gbc_param_grid[0]['max_depth'])\n",
    "    \n",
    "    #XGBoost Parameter Grid\n",
    "    xgb_param_grid = {'nthread':[NUM_CORES], \n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], \n",
    "              'max_depth': [i for i in range (10, 50, 10)],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'seed': [RANDOM_STATE]}\n",
    "    \n",
    "    xgb_px_len = len(xgb_param_grid[0]['n_estimators'])\n",
    "    xgb_py_len = len(xgb_param_grid[0]['max_depth'])\n",
    "\n",
    "    # Random Forest\n",
    "    print('\\tRandom Forest')\n",
    "\n",
    "    try :\n",
    "\n",
    "        rfc_results = pickle.load(open(RFC_GRID_SEARCH_PATH, 'rb'))\n",
    "        param_selection_heat_map(rfc_results, rfc_px_len, rfc_py_len, GRID_SEARCH_CV_FOLDS, RFC_GRID_SEARCH_GRAPH_PATH)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "\n",
    "        rfc = RandomForestClassifier()\n",
    "        clf = GridSearchCV(estimator=rfc, param_grid=rfc_param_grid, cv=GRID_SEARCH_CV_FOLDS, n_jobs=NUM_CORES)\n",
    "        clf.fit(x_train, y_train)\n",
    "        rfc_results = clf.cv_results_\n",
    "        pickle.dump(rfc_results, open(RFC_GRID_SEARCH_PATH, 'wb'))\n",
    "        param_selection_heat_map(rfc_results, rfc_px_len, rfc_py_len, GRID_SEARCH_CV_FOLDS, RFC_GRID_SEARCH_GRAPH_PATH)\n",
    "\n",
    "    # Gradient Boosted Trees \n",
    "    \n",
    "    print('\\tGradient Boosted Trees')\n",
    "\n",
    "    try:\n",
    "\n",
    "        gbc_results = pickle.load(open(GBC_GRID_SEARCH_PATH, 'rb')) \n",
    "        param_selection_heat_map(gbc_results, gbc_px_len, gbc_py_len, GRID_SEARCH_CV_FOLDS, GBC_GRID_SEARCH_GRAPH_PATH)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "\n",
    "        gbc = GradientBoostingClassifier()\n",
    "        clf = GridSearchCV(estimator=gbc, param_grid=gbc_param_grid, cv=GRID_SEARCH_CV_FOLDS, n_jobs=NUM_CORES)\n",
    "        clf.fit(x_train, y_train)\n",
    "        gbc_results = clf.cv_results_\n",
    "        pickle.dump(gbc_results, open(GBC_GRID_SEARCH_PATH, 'wb'))\n",
    "        param_selection_heat_map(gbc_results, gbc_px_len, gbc_py_len, GRID_SEARCH_CV_FOLDS, GBC_GRID_SEARCH_GRAPH_PATH)\n",
    "    \n",
    "    #XGBoost\n",
    "    \n",
    "    print('\\XGBoost')\n",
    "\n",
    "    try:\n",
    "\n",
    "        gbc_results = pickle.load(open(XGB_GRID_SEARCH_PATH, 'rb')) \n",
    "        param_selection_heat_map(xgb_results, xgb_px_len, xgb_py_len, GRID_SEARCH_CV_FOLDS, XGB_GRID_SEARCH_GRAPH_PATH)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "\n",
    "        xgb = XGBClassifier()\n",
    "        clf = GridSearchCV(estimator=xgb, param_grid=xgb_param_grid, cv=GRID_SEARCH_CV_FOLDS, n_jobs=NUM_CORES)\n",
    "        clf.fit(x_train, y_train)\n",
    "        xgb_results = clf.cv_results_\n",
    "        pickle.dump(xgb_results, open(xgb_GRID_SEARCH_PATH, 'wb'))\n",
    "        param_selection_heat_map(xgb_results, xgb_px_len, xgb_py_len, GRID_SEARCH_CV_FOLDS, XGB_GRID_SEARCH_GRAPH_PATH)\n",
    "    \n",
    "    \n",
    "    #################### \n",
    "    # Final Train/Test # \n",
    "    #################### \n",
    "\n",
    "    print('Final Train/Test')\n",
    "\n",
    "    try:\n",
    "\n",
    "        final_scores = pickle.load(open(FINAL_RESULTS_PATH, 'rb'))\n",
    "\n",
    "    except FileNotFoundError:\n",
    "\n",
    "        RFC_OPT_MAX_DEPTH = 1\n",
    "        RFC_OPT_N_ESTIMATORS = 10\n",
    "        GBC_OPT_MAX_DEPTH = 1\n",
    "        GBC_OPT_N_ESTIMATORS = 10 \n",
    "        XGB_OPT_MAX_DEPTH = 1\n",
    "        XGB_OPT_N_ESTIMATORS = 10\n",
    "\n",
    "        final_scores = {}\n",
    "        for i in range(1, 18):\n",
    "            rfc = RandomForestClassifier(max_depth=RFC_OPT_MAX_DEPTH, n_estimators=RFC_OPT_N_ESTIMATORS, n_jobs=NUM_CORES, random_state=RANDOM_STATE)\n",
    "            gbc = GradientBoostingClassifier(max_depth=GBC_OPT_MAX_DEPTH, n_estimators=GBC_OPT_N_ESTIMATORS, random_state=RANDOM_STATE)\n",
    "            xgb = XGBClassifier(max_depth=XGB_OPT_MAX_DEPTH, n_estimators=XGB_OPT_N_ESTIMATORS, random_state=RANDOM_STATE)\n",
    "            final_scores[i] = {}\n",
    "            final_scores[i]['rfc'] = cross_val_score(rfc, xs[i], ys[i], cv=CV_FOLDS, n_jobs=NUM_CORES)\n",
    "            final_scores[i]['gbc'] = cross_val_score(gbc, xs[i], ys[i], cv=CV_FOLDS, n_jobs=NUM_CORES)\n",
    "            final_scores[i]['xgb'] = cross_val_score(xgb, xs[i], ys[i], cv=CV_FOLDS, n_jobs=NUM_CORES)\n",
    "\n",
    "        pickle.dump(final_scores, open(FINAL_RESULTS_PATH, 'wb'))\n",
    "\n",
    "    fig, axarr = plt.subplots(5, 4, figsize=(25, 25))\n",
    "    for i in range(1, 18):\n",
    "        a, b = final_scores[i]['rfc'], final_scores[i]['gbc']\n",
    "        row, col = int((i-1)/4), (i-1)%4\n",
    "        axarr[row][col].boxplot([a, b])\n",
    "        axarr[row][col].set_title('Body Zone %s' % (i))\n",
    "        axarr[row][col].set_xticklabels(['RFC', 'GBC'])\n",
    "        axarr[row][col].set_ylabel('Accuracy')\n",
    "    for i in range(1, 4): axarr[4][i].axis('off')\n",
    "    plt.savefig(FINAL_RESULTS_GRAPH_PATH)\n",
    "\n",
    "if __name__ == '__main__' : main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
